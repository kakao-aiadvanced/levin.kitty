from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever

def load_documents(urls: list[str]) -> list[Document]:
    loader = WebBaseLoader(urls)
    docs = loader.load()
    return docs

def split_documents(docs: list[Document]) -> list[Document]:
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=100,
        chunk_overlap=10,
        length_function=len,
        is_separator_regex=False,
    )
    texts = text_splitter.split_documents(docs)
    return texts

def create_vector_store(texts: list[Document]) -> BaseRetriever:
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
    )
    vector_store = Chroma(
        collection_name="lilianweng",
        embedding_function=embeddings,
    )
    vector_store.add_documents(texts)
    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 6}
    )
    return retriever

# 5. ê´€ë ¨ì„± í‰ê°€

prompt_template = PromptTemplate(
    input_variables=["query", "document_chunk"],
    template="""
ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ê²€ìƒ‰ëœ ë¬¸ì„œ ì²­í¬ ê°„ì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

**ì‚¬ìš©ì ì¿¼ë¦¬:** {query}

**ê²€ìƒ‰ëœ ë¬¸ì„œ ì²­í¬:** {document_chunk}

**ì§€ì‹œì‚¬í•­:**
- ë¬¸ì„œ ì²­í¬ê°€ ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆê±°ë‚˜ ì¿¼ë¦¬ì— ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤ë©´ ê´€ë ¨ìˆìŒìœ¼ë¡œ íŒë‹¨
- ë¬¸ì„œ ì²­í¬ê°€ ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ì „í˜€ ë‹¤ë¥¸ ì£¼ì œì´ê±°ë‚˜ ë‹µë³€ì— ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ê´€ë ¨ì—†ìŒìœ¼ë¡œ íŒë‹¨

**ì¶œë ¥ í˜•ì‹:**
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{"relevance": "yes"}} ë˜ëŠ” {{"relevance": "no"}}

ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
)

def filter_relevant_documents(query, documents, chain):
    """
    ì¿¼ë¦¬ì™€ ê´€ë ¨ì„±ì´ ìˆëŠ” ë¬¸ì„œë“¤ë§Œ í•„í„°ë§í•´ì„œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        query (str): ì‚¬ìš©ì ì¿¼ë¦¬
        documents (list): ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        chain: ê´€ë ¨ì„± í‰ê°€ ì²´ì¸
    
    Returns:
        list: ê´€ë ¨ì„±ì´ ìˆëŠ” ë¬¸ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    """
    relevant_docs = []
    
    for i, doc in enumerate(documents, 1):
        result = chain.invoke({"query": query, "document_chunk": doc.page_content})
        print(f"\n[ë¬¸ì„œ {i}] ê´€ë ¨ì„±: {result}")
        
        if result.get('relevance') == 'yes':
            relevant_docs.append(doc)
            print(f"âœ… ê´€ë ¨ ë¬¸ì„œë¡œ ì„ íƒë¨")
        else:
            print(f"âŒ ê´€ë ¨ì„± ì—†ìŒ")
        print("-" * 30)
    
    return relevant_docs

# 6. ì¼€ì´ìŠ¤ 
# All Yes Case: query = "LLM"
# All Non Case: query = "Jeju Island"    

# 8. RAG ë‹µë³€ ìƒì„±
rag_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì°¸ê³  ë¬¸ì„œ:**
{context}

**ì§ˆë¬¸:** {question}

**ì§€ì‹œì‚¬í•­:**
- ìœ„ì˜ ì°¸ê³  ë¬¸ì„œë“¤ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  í•´ì£¼ì„¸ìš”
- í•œêµ­ì–´ë¡œ ìì„¸í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”
- ê°€ëŠ¥í•˜ë©´ ì°¸ê³ í•œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¸ìš©í•´ì£¼ì„¸ìš”
- ë‹µë³€ ë§ˆì§€ë§‰ì— **ì¶œì²˜** ì„¹ì…˜ì„ ë§Œë“¤ì–´ ì°¸ê³ í•œ ë¬¸ì„œë“¤ì˜ URLì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”

**ë‹µë³€:**
"""
)

def generate_rag_answer(query, relevant_docs, llm):
    """
    ê´€ë ¨ ë¬¸ì„œë“¤ì„ ì‚¬ìš©í•´ì„œ RAG ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        query (str): ì‚¬ìš©ì ì§ˆë¬¸
        relevant_docs (list): ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë“¤
        llm: ì–¸ì–´ ëª¨ë¸
    
    Returns:
        str: ìƒì„±ëœ ë‹µë³€
    """
    if not relevant_docs:
        return "ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ê´€ë ¨ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸° (ì¶œì²˜ URL í¬í•¨)
    context_parts = []
    source_urls = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set
    
    for i, doc in enumerate(relevant_docs):
        source_url = doc.metadata.get('source', 'Unknown')
        source_urls.add(source_url)
        context_parts.append(f"[ë¬¸ì„œ {i+1}]\n{doc.page_content}\nì¶œì²˜: {source_url}")
    
    context = "\n\n".join(context_parts)
    
    # ì¶œì²˜ URL ëª©ë¡ ì¶”ê°€
    if source_urls and 'Unknown' not in source_urls:
        context += f"\n\n**ì°¸ê³  ë¬¸ì„œ URL ëª©ë¡:**\n"
        for url in sorted(source_urls):
            context += f"- {url}\n"
    
    rag_chain = rag_template | llm
    response = rag_chain.invoke({"context": context, "question": query})
    
    return response.content if hasattr(response, 'content') else str(response)

# 9. Hallucination ì²´í¬ ë° ì¬ìƒì„±
hallucination_template = PromptTemplate(
    input_variables=["context", "question", "answer"],
    template="""
ì œê³µëœ ë¬¸ì„œë“¤ê³¼ ìƒì„±ëœ ë‹µë³€ì„ ë¹„êµí•˜ì—¬, ë‹µë³€ì— Hallucination(í™˜ê°)ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.

**ì›ë³¸ ë¬¸ì„œë“¤:**
{context}

**ì§ˆë¬¸:** {question}

**ìƒì„±ëœ ë‹µë³€:** {answer}

**í‰ê°€ ê¸°ì¤€:**
1. ë‹µë³€ì˜ ëª¨ë“  ë‚´ìš©ì´ ì œê³µëœ ë¬¸ì„œë“¤ì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œê°€?
2. ë‹µë³€ì— ë¬¸ì„œì— ì—†ëŠ” ì¶”ê°€ ì •ë³´ë‚˜ ì¶”ì¸¡ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
3. ë‹µë³€ì´ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì •í™•íˆ ë°˜ì˜í•˜ê³  ìˆëŠ”ê°€?

**ì¶œë ¥ í˜•ì‹:**
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{"hallucination": "yes/no", "explanation": "í•œêµ­ì–´ë¡œ íŒë‹¨ ì´ìœ  ì„¤ëª…", "confidence": "high/medium/low"}}

ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
)

def check_hallucination(context, question, answer, llm):
    """
    RAG ë‹µë³€ì— Hallucinationì´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        context (str): ì›ë³¸ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸
        question (str): ì‚¬ìš©ì ì§ˆë¬¸
        answer (str): ìƒì„±ëœ ë‹µë³€
        llm: ì–¸ì–´ ëª¨ë¸
    
    Returns:
        dict: Hallucination í‰ê°€ ê²°ê³¼
    """
    hallucination_chain = hallucination_template | llm | JsonOutputParser()
    result = hallucination_chain.invoke({
        "context": context, 
        "question": question, 
        "answer": answer
    })
    return result

def generate_rag_with_hallucination_check(query, relevant_docs, llm, max_retries=1):
    """
    Hallucination ì²´í¬ì™€ í•¨ê»˜ RAG ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì¬ì‹œë„ í¬í•¨)
    
    Args:
        query (str): ì‚¬ìš©ì ì§ˆë¬¸
        relevant_docs (list): ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë“¤
        llm: ì–¸ì–´ ëª¨ë¸
        max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    Returns:
        tuple: (ìµœì¢…_ë‹µë³€, hallucination_ê²°ê³¼ë“¤)
    """
    if not relevant_docs:
        return "ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
    
    context = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}]\n{doc.page_content}"
        for i, doc in enumerate(relevant_docs)
    ])
    
    hallucination_results = []
    current_answer = generate_rag_answer(query, relevant_docs, llm)
    
    for attempt in range(max_retries + 1):
        print(f"\nğŸ” Hallucination ì²´í¬ (ì‹œë„ {attempt + 1}):")
        print("=" * 60)
        
        # Hallucination ì²´í¬
        hallucination_result = check_hallucination(context, query, current_answer, llm)
        hallucination_results.append({
            'attempt': attempt + 1,
            'result': hallucination_result
        })
        
        print(f"Hallucination ì—¬ë¶€: {hallucination_result['hallucination']}")
        print(f"ì‹ ë¢°ë„: {hallucination_result['confidence']}")
        print(f"ì„¤ëª…: {hallucination_result['explanation']}")
        
        if hallucination_result['hallucination'] == 'no':
            print("âœ… ë‹µë³€ì´ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•©ë‹ˆë‹¤.")
            break
        else:
            print("âš ï¸  ë‹µë³€ì— Hallucinationì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ì¬ì‹œë„ ê°€ëŠ¥í•œ ê²½ìš°
            if attempt < max_retries:
                print(f"ğŸ”„ ë‹µë³€ì„ ì¬ìƒì„±í•©ë‹ˆë‹¤... (ì¬ì‹œë„ {attempt + 1}/{max_retries})")
                
                # ì¬ìƒì„±ìš© ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                improved_rag_template = PromptTemplate(
                    input_variables=["context", "question", "previous_issues"],
                    template="""
ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì°¸ê³  ë¬¸ì„œ:**
{context}

**ì§ˆë¬¸:** {question}

**ì´ì „ ë‹µë³€ì˜ ë¬¸ì œì :** {previous_issues}

**ì¤‘ìš”í•œ ì§€ì‹œì‚¬í•­:**
- ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œë“¤ì—ì„œë§Œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì£¼ì„¸ìš”
- ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ ìƒì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ë¬¸ì„œì—ì„œ ì§ì ‘ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”
- ë‹µë³€ ë§ˆì§€ë§‰ì— **ì¶œì²˜** ì„¹ì…˜ì„ ë§Œë“¤ì–´ ì°¸ê³ í•œ ë¬¸ì„œë“¤ì˜ URLì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”

**ë‹µë³€:**
"""
                )
                
                improved_chain = improved_rag_template | llm
                current_answer = improved_chain.invoke({
                    "context": context, 
                    "question": query,
                    "previous_issues": hallucination_result['explanation']
                }).content if hasattr(improved_chain.invoke({
                    "context": context, 
                    "question": query,
                    "previous_issues": hallucination_result['explanation']
                }), 'content') else str(improved_chain.invoke({
                    "context": context, 
                    "question": query,
                    "previous_issues": hallucination_result['explanation']
                }))
                
                print(f"\nğŸ¤– ì¬ìƒì„±ëœ ë‹µë³€:")
                print("=" * 60)
                print(current_answer)
                print("=" * 60)
            else:
                print(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ë‹µë³€ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        print("=" * 60)
    
    return current_answer, hallucination_results

if __name__ == "__main__":
    
    # ë¬¸ì„œ ë§í¬
    urls = [
        "https://lilianweng.github.io/posts/2023-06-23-agent/",
        "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/",
        "https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/",
    ]
    
    # ì¿¼ë¦¬
    query = "Jeju Island"
    query = "agent memory"
    
    print(f"ğŸ” ì¿¼ë¦¬: '{query}'")
    print("=" * 60)
    
    # 1. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
    print("ğŸ“ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    docs = load_documents(urls)
    texts = split_documents(docs)
    print(f"âœ… {len(texts)}ê°œ ë¬¸ì„œ ì²­í¬ ìƒì„± ì™„ë£Œ")
    
    # 2. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ê²€ìƒ‰
    print("ğŸ” ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
    retriever = create_vector_store(texts)
    retrieved_documents = retriever.invoke(query)
    print(f"âœ… {len(retrieved_documents)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
    
    # 3. ê´€ë ¨ì„± í‰ê°€ ë° í•„í„°ë§
    print("\nğŸ“‹ ê´€ë ¨ì„± í‰ê°€ ì‹œì‘...")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)
    chain = prompt_template | llm | JsonOutputParser()
    relevant_documents = filter_relevant_documents(query, retrieved_documents, chain)
    
    print(f"\nğŸ“Š ê²°ê³¼: ì „ì²´ {len(retrieved_documents)}ê°œ ë¬¸ì„œ ì¤‘ {len(relevant_documents)}ê°œê°€ ê´€ë ¨ì„± ìˆìŒ")
    
    # 4. RAG ë‹µë³€ ìƒì„± (Hallucination ì²´í¬ ë° ì¬ìƒì„± í¬í•¨)
    if relevant_documents:
        print(f"\nğŸ¤– '{query}'ì— ëŒ€í•œ RAG ë‹µë³€ ìƒì„± ì‹œì‘...")
        print("=" * 60)
        
        final_answer, hallucination_history = generate_rag_with_hallucination_check(
            query, relevant_documents, llm, max_retries=1
        )
        
        print(f"\nğŸ“ ìµœì¢… ë‹µë³€:")
        print("=" * 60)
        print(final_answer)
        print("=" * 60)
        
        # 5. ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½:")
        print("=" * 60)
        print(f"ì´ ì‹œë„ íšŸìˆ˜: {len(hallucination_history)}")
        for i, result in enumerate(hallucination_history):
            status = "âœ… í†µê³¼" if result['result']['hallucination'] == 'no' else "âš ï¸  Hallucination ê°ì§€"
            print(f"ì‹œë„ {result['attempt']}: {status}")
        
        if hallucination_history[-1]['result']['hallucination'] == 'no':
            print("ğŸ‰ ìµœì¢… ë‹µë³€ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âš ï¸  ìµœì¢… ë‹µë³€ì— ì—¬ì „íˆ Hallucinationì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("=" * 60)
    else:
        print("\nâš ï¸  ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œê°€ ì—†ì–´ RAG ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
     